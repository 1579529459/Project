#-*- codeing = utf-8 -*-
#@Time : 2020/3/3 17:51
#@Author : 李巍
#@File : spider.py
#@Software: PyCharm

from bs4 import BeautifulSoup     #网页解析，获取数据
import re       #正则表达式，进行文字匹配
import urllib.request,urllib.error      #制定URL，获取网页数据
import xlwt     #进行excel操作
import sqlite3  #进行SQLite数据库操作
import os
import time
import requests
findImgSrc=re.compile(r'<img.*="(.*?)"',re.S)

baseurl = "https://5grvlb.xyz:1443/h/787"
def main():
    baseurl = "https://5grvlb.xyz:1443/h/787"
    #1.爬取网页
    download()  ##其中就有 发出请求 解析下载链接的过程！
   
   
 
  #



#爬取网页
def getData(baseurl):
    start="20"
    datalist = []
    for i in range(2):       #调用获取页面信息的函数，10次
        url = baseurl + start
        html = askURL(url)      #保存获取到的网页源码
        start=str(int(start)+1)
        print(start)
         
        soup = BeautifulSoup(html,"html.parser")
        for item in soup.find_all('img'):     #查找符合要求的字符串，形成列表
            #print(item)   #测试：查看电影item全部信息
            data = []    #保存一部电影的所有信息
            item = str(item)

         

            imgSrc = re.findall(findImgSrc,item)[0]
            data.append(imgSrc)                     #添加图片

        

            datalist.append(data)       #把处理好的一部电影信息放入datalist

    return datalist



#得到指定一个URL的网页内容
def askURL(url):
    head = {                #模拟浏览器头部信息，向豆瓣服务器发送消息
        "User-Agent": "Mozilla / 5.0(Windows NT 10.0; Win64; x64) AppleWebKit / 537.36(KHTML, like Gecko) Chrome / 80.0.3987.122  Safari / 537.36"
    }
                            #用户代理，表示告诉豆瓣服务器，我们是什么类型的机器、浏览器（本质上是告诉浏览器，我们可以接收什么水平的文件内容）

    request = urllib.request.Request(url,headers=head)
    html = ""
    try:
        response = urllib.request.urlopen(request)
        html = response.read().decode("utf-8")
        #print(html)
    except Exception as e:
        pass
    return html




#保存数据



def download():
    t3=time.time()

 
    
    datalist = getData(baseurl)
    #print(datalist)
   

    i=0
    for j in range(len(datalist)):

        url=datalist[j][0]

        d='C:\\tu\\'

        path=d+url.split('/')[-1]

     

        if not os.path.exists(d):

            os.mkdir(d)

        if not os.path.exists(path):

            print("正在下载第%d张图片.........."%(j+1))
            t1=time.time()
            r=requests.get(url)
            t2=time.time()

                #r.raise_for_status()
               

            with open(path,'wb') as f:

                f.write(r.content)

                f.close()

                print("图片下载并存入本地图库成功！用时------%.3f秒"%(t2-t1))
                i+=1

        else:

            pass
    t4=time.time()
    print("\n\n")
    print("爬取完毕！总用时%.3f秒,3秒后将打开本地图库....."%(t4-t3)) 
    time.sleep(3)
    path = r'C:\tu'
    os.startfile(path)

#====================================================================================================


if __name__ == "__main__":          #当程序执行时
#调用函数
    main()
    #init_db("movietest.db")
    print("爬取完毕！")
