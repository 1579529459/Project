#-*- codeing = utf-8 -*-
#@Time : 2020/3/3 17:51
#@Author : 李巍
#@File : spider.py
#@Software: PyCharm

from bs4 import BeautifulSoup     #网页解析，获取数据
import re       #正则表达式，进行文字匹配
import urllib.request,urllib.error      #制定URL，获取网页数据
import xlwt     #进行excel操作
import sqlite3  #进行SQLite数据库操作
import requests
import os
import time


baseurl = "https://5grvlb.xyz:1443/h/786"  #目标网站框架*******************************************
findImgSrc=re.compile(r'<img.*="(.*?)"',re.S)



def main():
    
    #1.爬取网页
    datalist = getData(baseurl)


    download()
     
   
    
   
    
    #2.影片图片链接入表
    

    #download()

#====================================解析数据部分=======================================

def getData(baseurl): 
    
    #记录已经爬取的网页码(共五位)：786( 25-99)

    start="75"#起始网站尾标*********************************************************************************************
    a=26     #a调用获取页面信息的函数，10次********一次大概3-4张 ***********************************************************







    datalist = []
     
    for i in range(a):      
        url = baseurl+start


        start=str(int(start)+1)
       
    
        
        
        
        
        html = askURL(url)#保存获取到的网页源码
       
       
         # 2.逐一解析数据
        soup = BeautifulSoup(html,"html.parser")
        
        for item in soup.find_all('img'):     #查找符合要求的字符串，形成列表
            print(item)   #测试：查看电影item全部信息
            data = []    #保存一部电影的所有信息
            item = str(item)

         

            imgSrc = re.findall(findImgSrc,item)[0]
            #print(imgSrc)
            data.append(imgSrc)#添加图片              

            datalist.append(data)#把处理好的一部电影信息放入datalist
            #print(datalist)
            #1print("\n")
        print("\n\n")
       
        
       

    return datalist

#====================================================================================================


#=================================    下载部分   ==================================================
def download():
    t3=time.time()

 
    
    datalist = getData(baseurl)
    #print(datalist)
   

    i=0
    for j in range(len(datalist)):

        url=datalist[j][0]

        d='C:\\tu\\'

        path=d+url.split('/')[-1]

     

        if not os.path.exists(d):

            os.mkdir(d)

        if not os.path.exists(path):

            print("正在下载第%d张图片.........."%(j+1))
            t1=time.time()
            r=requests.get(url)
            t2=time.time()

                #r.raise_for_status()
               

            with open(path,'wb') as f:

                f.write(r.content)

                f.close()

                print("图片下载并存入本地图库成功！用时------%.3f秒"%(t2-t1))
                i+=1

        else:

            pass
    t4=time.time()
    print("\n\n")
    print("爬取完毕！总用时%.3f秒,3秒后将打开本地图库....."%(t4-t3)) 
    time.sleep(3)
    path = r'C:\tu'
    os.startfile(path)

#====================================================================================================



def askURL(url):

    try:

        head = {                
                "User-Agent": "Mozilla / 5.0(Windows NT 10.0; Win64; x64) AppleWebKit / 537.ome / 80.0.3987.122  Safari / 537.36"
        }
                            

        request = urllib.request.Request(url,headers=head)

        html = ""
 
        response = urllib.request.urlopen(request)
        html = response.read().decode("utf-8")
    except Exception :
        pass



        
       
   
    return html










if __name__ == "__main__":          #当程序执行时
#调用函数
    main()
    #init_db("movietest.db")
    
