
from urllib import request
from lxml import html
from lxml import etree
import requests
import os
from fake_useragent import UserAgent
import time
from tkinter import *
etree = html.etree


 




   #爬取页数       推荐1  共12页网页

#value=0



s_1="https://pic.netbian.com"


def download(tu,mz,yema,zhang):

    #yema=yema
    #tu=tu
    #mz=mz
    #s_1="https://pic.netbian.com"
     
    
    
    
        #print(tu[j])
        #print(s)    #检查图片完整路径
        
        
    url=s_1+tu[0]
        #print(url)   #检查图片完整路径
        #break

    d='C:\\meitu\\'

    path=d+url.split('/')[-1]

     

    if not os.path.exists(d):

        os.mkdir(d)
        print("创建本地图库成功！！")

    if not os.path.exists('C:\\meitu\\'+mz+'.jpg'):

        print(">>正在下载---第%d页---第%d张图片......>>>>>>%s"%(yema,zhang,mz))
            
        r=requests.get(url)
            
       
               

        with open('C:\\meitu\\'+mz+'.jpg','wb') as f:

            f.write(r.content)

            f.close()

            print(">>>---第%d页---第%d张---图片下载并存入本地图库成功！\n"%(yema,zhang))
            
              

    else:
        print(">>>---第%d页--第%d张---图片已存在！！！！\n"%(yema,zhang))   #下载工作
    


def main():
    global value
    url = url_in.get()
    n=int(url)
    
    while value<n:
        yema=value+1
        if value == 0:
            baseurl = "https://pic.netbian.com/4kmeinv/index.html"
        else:
  
            baseurl = "https://pic.netbian.com/4kmeinv/index_"+str(yema)+".html"  
   
    
  
        headers={'User-Agent':UserAgent().random}



        
   
        rq=requests.get(baseurl,headers=headers)
    
        rq.encoding=("gbk")
    
    #print(rq.text)
    #break
 
        s=etree.HTML(rq.text)

   
   

    
       
        s = s.xpath('//div[@id="main"]//li/a/@href')
        zhang = 1    #每页从第一张开始下载！！
        for i in s:
            url_1=s_1+i
            rq=requests.get(url_1,headers=headers)
    
            rq.encoding=("gbk")
    
        #print(rq.text)
        #break
 
            s=etree.HTML(rq.text)


   
             
            tu = s.xpath('//a[@id="img"]/img/@src')
        #print(tu)
        #break
  

    
    
            mz = s.xpath('//a[@id="img"]/img/@alt')
    #print(mz)
    #break
     

            mz=mz[0]
   
        
            download(tu,mz,yema,zhang)
            zhang+=1
  
        
        
        value+=1
        yema+=1    #获取当前页面下进入每套套图的链接（一页30套！）
    #except Exception:
        #pass

        


                                                         

    print("爬取完毕！！3秒后将打开本地图库.....")  #收尾工作
    time.sleep(3)
    path = r'C:\meitu'
    os.startfile(path)  





global url_input,text
	#创建空白窗口,作为主载体
root = Tk()
root.title('测试——魏哥爬虫怕美女！')
#窗口的大小，后面的加号是窗口在整个屏幕的位置
root.geometry('550x400+1000+279')
	#标签控件，窗口中放置文本组件
Label(root,text='请输入要爬取网页的url:',font=("华文行楷",20),fg='black').grid()



	#定位 pack包 place位置 grid是网格式的布局
	
	#Entry是可输入文本框
url_input=Entry(root,font=("微软雅黑",15))
url_input.grid(row=0,column=1)
Label(root,text='请输入要爬取的页数:',font=("华文行楷",20),fg='black').grid(row=2)
url_in=Entry(root,font=("微软雅黑",15))
url_in.grid(row=2,column=1)
#列表控件
text=Listbox(root,font=('微软雅黑',15),width=45,height=9)
	#columnspan 组件所跨越的列数
text.grid(row=1,columnspan=2)

	#设置按钮 sticy对齐方式，N S W E
o=str(url_in.get())
print(o)
n=1

value=0
button =Button(root,text='开始下载',font=("微软雅黑",15),command=main).grid(row=3,column=0,sticky=W)
button =Button(root,text='退出',font=("微软雅黑",15),command=root.quit).grid(row=3,column=1,sticky=E)
	#使得窗口一直存在

mainloop()



